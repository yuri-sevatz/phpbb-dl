#!/bin/env python
import argparse
import os
import phpbb
import re
import subprocess

from cvm.controller import Browser
from datetime import datetime
from dateutil import tz
from http.cookiejar import MozillaCookieJar
from urllib.parse import urlparse
from requests.exceptions import ConnectionError
from selenium.common.exceptions import TimeoutException
from selenium.webdriver import Chrome, ChromeOptions


process_begin = datetime.now(tz=tz.tzlocal())


def valid_datetime(s):
    try:
        return datetime.strptime(s, "%Y-%m-%dT%H:%M:%SZ").replace(tzinfo=tz.tzutc())
    except ValueError:
        try:
            return datetime.strptime(s, "%Y-%m-%dT%H:%M:%S%z")
        except ValueError:
            raise argparse.ArgumentTypeError("Not a valid date: '{}'.".format(s))


def valid_dir(s):
    if not os.path.isdir(s):
        raise argparse.ArgumentTypeError("Not a valid dir: '{}'.".format(s))
    return s


parser = argparse.ArgumentParser(description='PhpBB Downloader')
parser.add_argument(
    '--username', '-u', type=str, action='store', default=None,
    help="username to supply to remote server if logging in"
)
parser.add_argument(
    '--password', '-p', type=str, action='store', default=None,
    help="password to supply to remote server if logging in"
)
parser.add_argument(
    '--output', '-o', type=valid_dir, action='store', default=os.path.curdir,
    help="output directory"
)
parser.add_argument(
    '--reverse', '-r', action='store_true', default=False,
    help="archive newer topics first"
)
parser.add_argument(
    '--incremental', '-i', action='store_true', default=False,
    help="save/load progress in <output>/.timestamp.chk"
)
parser.add_argument(
    '--full', '-f', action='store_true', default=False,
    help="restart progress in <output>/.timestamp.chk"
)
parser.add_argument(
    '--checkpoint', '-c', type=valid_datetime, action='store', default=None,
    help="override progress on start with date/time (e.g. {checkpoint})".format(
        checkpoint=process_begin.strftime("%Y-%m-%dT%H:%M%z")
    )
)
parser.add_argument(
    '--begin', '-b', type=valid_datetime, action='store', default=None,
    help="begin post date/time range (e.g. {begin})".format(
        begin=process_begin.strftime("%Y-%m-%dT%H:%M%z")
    )
)
parser.add_argument(
    '--end', '-e', type=valid_datetime, action='store', default=None,
    help="end post date/time range (e.g. {end})".format(
        end=process_begin.strftime("%Y-%m-%dT%H:%M%z")
    )
)
parser.add_argument(
    '--keep', '-k', action='store_true', default=False,
    help="keep session at <output>/.cookies.txt"
)
parser.add_argument(
    '--simulate', '-s', action='store_true', default=False,
    help="simulate execution without writing to disk"
)
parser.add_argument(
    '--tunnel', '-t', type=str, action='store', default=None,
    help="Proxy Server (e.g. 127.0.0.1:8118)"
)
parser.add_argument(
    'url', type=str, nargs='+',
    help="sequence of urls to access, of format: {}".format(str([
        "<phpbb_root>/index.php?login/",
        "<phpbb_root>/index.php",
        "<phpbb_root>/viewforum.php?f=<forum_id>",
        "<phpbb_root>/viewtopic.php?t=<topic_id>",
    ]))
)

args = parser.parse_args()

begin = args.begin
end = args.end

checkpoint = None
checkpoint_path = os.path.join(args.output, '.timestamp.chk')

proxies = {'http': args.tunnel, 'https': args.tunnel, 'ftp': args.tunnel} if args.tunnel else {}

if not args.full and (args.incremental or args.checkpoint):
    try:
        checkpoint = args.checkpoint if args.checkpoint else datetime.fromtimestamp(os.stat(checkpoint_path).st_mtime).replace(tzinfo=tz.tzutc(), second=0)
        if begin and not begin <= checkpoint:
            raise ValueError(
                (
                    "Checkpoint not in range [begin, end]: "
                    "requires -b [--begin] {begin} <= -c [--checkpoint] {checkpoint}"
                ).format(begin=begin, checkpoint=checkpoint)
            )
        if end and not checkpoint <= end:
            raise ValueError(
                (
                    "Checkpoint not in range [begin, end]: "
                    "requires -c [--checkpoint] {checkpoint} <= -e [--end] {end}"
                ).format(checkpoint=checkpoint, end=end)
            )
        begin = checkpoint if not begin else max(begin, checkpoint)
    except FileNotFoundError:
        pass
else:
    if begin and end and not begin <= end:
        raise ValueError(
            (
                "Cannot define range [begin, end]: "
                "requires -b [--begin] {begin} <= -e [--end] {end}"
            ).format(begin=args.begin, end=args.end)
        )


def windows_filename(filename: str):
    return filename\
        .replace('<', '')\
        .replace('>', '')\
        .replace(':', '')\
        .replace('"', '')\
        .replace('/', '')\
        .replace('\\', '')\
        .replace('|', '')\
        .replace('?', '')\
        .replace('*', '')


MAX_RETRIES = 5

def handle_topic(path: str):
    print("handle_topic: {}".format(browser.url))
    hrefs = set()
    if args.reverse:
        topic = browser.load(phpbb.Topic())
        if topic.nav:
            if topic.nav.last:
                print('Topic >>')
                topic.nav.last.click()
                topic.nav.last.unload()
    found_range = False
    while True:
        topic = browser.load(phpbb.Topic())
        for post in (topic.posts if not args.reverse else reversed(topic.posts)):
            if post.time:
                modified = valid_datetime(post.time.attribute('datetime'))
                if (begin and begin > modified) or (end and modified < end):
                    if found_range:
                        break
                    continue
                else:
                    found_range = True
            for attachment in post.attachments:
                name = attachment.filename.text
                href = attachment.download.attribute('href')
                hrefs.add((name,href))
        else:
            if topic.nav:
                if args.reverse:
                    if topic.nav.prev:
                        print('Topic <')
                        try:
                            topic.nav.prev.click()
                            topic.nav.prev.unload()
                        except TimeoutException as e:
                            for i in range(MAX_RETRIES):
                                try:
                                    browser.refresh()
                                    topic.nav.prev.unload()
                                    break
                                except TimeoutException as e:
                                    if i == MAX_RETRIES:
                                        raise e
                        continue
                else:
                    if topic.nav.next:
                        print('Topic >')
                        try:
                            topic.nav.next.click()
                            topic.nav.next.unload()
                        except TimeoutException as e:
                            for i in range(MAX_RETRIES):
                                try:
                                    browser.refresh()
                                    topic.nav.next.unload()
                                    break
                                except TimeoutException as e:
                                    if i == MAX_RETRIES:
                                        raise e
                        continue
        break
    for name, href in hrefs:
        match = re.match(r"attachments/(?:.+\.)?(\d+)/", urlparse(href).query)
        download = os.path.join(path, '{}.{}'.format(match.group(1), name.replace('/', '')))
        if not os.path.exists(download):
            print('GET {} ... '.format(href), end='', flush=True)
            if not args.simulate:
                if not os.path.exists(path):
                    os.makedirs(path)
                for i in range(MAX_RETRIES):
                    try:
                        browser.save(href, download, proxies=proxies)
                        print('Done!')
                        break
                    except ConnectionError as e:
                        if i == MAX_RETRIES:
                            raise e
                        else:
                            print("\nError: {}".format(e))


def handle_forum(path: str):
    print("handle_forum: {}".format(browser.url))
    hrefs = set()
    if not args.reverse:
        forum = browser.load(phpbb.Forum())
        if forum.nav:
            if forum.nav.last:
                print('Forum >>')
                forum.nav.last.click()
                forum.nav.last.unload()
    found_range = False
    while True:
        thread = browser.load(phpbb.Forum())
        for topic in (thread.topics if args.reverse else reversed(thread.topics)):
            if not topic.title:
                continue
            name = topic.title.text
            href = topic.title.attribute('href')
            if topic.time:
                modified = valid_datetime(topic.time.attribute('datetime'))
                if (begin and begin > modified) or (end and modified < end):
                    if found_range:
                        break
                    continue
                else:
                    found_range = True
            print('Topic: {} -> {}'.format(name, href))
            hrefs.add((name,href))
        else:
            if thread.nav:
                if args.reverse:
                    if thread.nav.next:
                        print('Forum >')
                        try:
                            thread.nav.next.click()
                            thread.nav.next.unload()
                        except TimeoutException as e:
                            for i in range(MAX_RETRIES):
                                try:
                                    browser.refresh()
                                    thread.nav.next.unload()
                                    break
                                except TimeoutException as e:
                                    if i == MAX_RETRIES:
                                        raise e
                        continue
                else:
                    if thread.nav.prev:
                        print('Forum <')
                        try:
                            thread.nav.prev.click()
                            thread.nav.prev.unload()
                        except TimeoutException as e:
                            for i in range(MAX_RETRIES):
                                try:
                                    browser.refresh()
                                    thread.nav.prev.unload()
                                    break
                                except TimeoutException as e:
                                    if i == MAX_RETRIES:
                                        raise e
                        continue


        break
    for name, href in hrefs:
        print(href)
        query = urlparse(href).query
        match = re.match(r"threads/(?:.+\.)?(\d+)/", query)
        directory = os.path.join(path, 'topic.{}.{}'.format(match.group(1), name.replace('/', '')))
        for i in range(MAX_RETRIES):
            try:
                browser.url = href
                break
            except TimeoutException as e:
                if i == MAX_RETRIES:
                    raise e
        handle_topic(directory)


def handle_index(path: str):
    print("handle_index: {}".format(browser.url))
    hrefs = []
    index = browser.load(phpbb.Index())
    for thread in index.threads:
        name = thread.title.text
        href = thread.title.attribute('href')
        print('Forum: {} -> {} '.format(name, href))
        try:
            modified = valid_datetime(thread.time.attribute('datetime'))
        except ValueError as e:
            print(e)
        else:
            hrefs.append((name,href))
    for name, href in hrefs:
        query = urlparse(href).query
        match = re.match(r"forums/(?:.+\.)?(\d+)/", query)
        directory = os.path.join(path, 'forum.{}.{}'.format(match.group(1), name.replace('/', '')))
        for i in range(MAX_RETRIES):
            try:
                browser.url = href
                break
            except TimeoutException as e:
                if i == MAX_RETRIES:
                    raise e
        handle_forum(directory)



def handle_login(path: str):
    print("handle_login: {}".format(browser.url))
    login = browser.load(phpbb.Login())
    login.username.input(args.username)
    login.password.input(args.password)
    login.submit.click()
    login.submit.unload()


def chrome():
    options = ChromeOptions()
    p = subprocess.Popen(
        ['chromium', '--version'],
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    )
    version, error = p.communicate()
    number = str(version).split(' ')[1]
    agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{number} Safari/537.36'.format(number=number)
    options.add_argument('--headless')
    options.add_argument('--window-size=1920,1080')
    options.add_argument("--user-agent={}".format(agent))
    options.add_argument('--blink-settings=imagesEnabled=false')
    if args.tunnel:
        options.add_argument("--proxy-server={}".format(args.tunnel))
    driver = Chrome(chrome_options=options)
    driver.set_page_load_timeout(300)
    return driver


browser = Browser(chrome())

jar = MozillaCookieJar(os.path.join(args.output, '.cookies.txt')) if args.keep else None
if args.keep and os.path.exists(jar.filename):
    jar.load()
    # FIXME: Un-quirk if w3c ever fixes this, or replace if Chromium fixes or breaks workaround:
    # https://github.com/w3c/webdriver/issues/1238
    browser.url = "https://www.google.com"
    browser.cookies.load(jar)

rpaths = [
    (r"/index\.php\?login(?:/[^\\]*)?$", handle_login),
    (r"/index\.php$", handle_index),
    (r"/index\.php\?forums/[^\\]+\.\d+/$", handle_forum),
    (r"/index\.php\?threads/[^\\]+\.\d+/$", handle_topic),
]

try:
    for url in args.url:
        for pattern, func in rpaths:
            if re.search(pattern, url):
                browser.url = url
                func(args.output)
                break
        else:
            raise ValueError("Url path must match one of {}".format(str([pattern for pattern, func in rpaths])))
    process_end = process_begin if not end else min(end, process_begin)
    if not args.simulate and (args.full or args.incremental):
        with open(checkpoint_path, 'a'):
            os.utime(checkpoint_path, (process_end.timestamp(), process_end.timestamp()))
    if args.keep:
        browser.cookies.save(jar)
        jar.save()
finally:
    browser.quit()

